{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRO-C112 Referencia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVe_ge-0KTVn"
      },
      "source": [
        "## Carga de datos\n",
        "\n",
        "**Estructura del directorio del conjunto de datos de la imagen**:\n",
        "\n",
        "**Nota: Los nombres de los directorios y sub-directorios que se muestran aquí son sólo para propósitos de explicación que pueden diferir del código.\n",
        "\n",
        "Supongamos que tenemos un directorio principal (carpeta) de las imágenes, entonces podemos subdividirlo en subdirectorios (subcarpetas) de imágenes de \"entrenamiento\" (*training*), \"validación\" (*validation*) y \"prueba\" (*testing*). \n",
        "\n",
        "Entonces los directorios de \"Entrenamiento\" contienen sub-directorios(sub-carpetas) llamados \"infectados\" (*infected*) y \"No infectados\" (*uninfected*))que contienen imágenes apropiadas en los respectivos sub-directorios.\n",
        "\n",
        "Del mismo modo, los directorios de \"validación\" y \"prueba\" también contienen subdirectorios (subcarpetas) denominados \"infectado\" y \"no infectado\" que contienen las imágenes adecuadas en los respectivos subdirectorios.\n",
        "\n",
        "\n",
        "**Entrenamiento**: Las imágenes de este directorio se utilizarán para el entrenamiento de los datos.\n",
        "\n",
        "**Validación**: Las imágenes de este directorio se utilizarán para validar el entrenamiento del modelo. El conjunto de datos de validación nos permite ver lo bien que los datos generalizan la clasificación.\n",
        "\n",
        "**Prueba**: Las imágenes de este directorio se utilizarán para probar lo bien que se ha entrenado el modelo.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1-AMSvB19tME043-_oC9BQJIydiVCuukb\" width= 600>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xCYT8gXKTVq",
        "outputId": "2121e8c7-dcc4-441d-c357-c2dc3d21b487"
      },
      "source": [
        "!git clone https://github.com/procodingclass/PRO-M3-Pneumothorax-Image-Dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PRO-M3-Pneumothorax-Image-Dataset'...\n",
            "remote: Enumerating objects: 637, done.\u001b[K\n",
            "remote: Total 637 (delta 0), reused 0 (delta 0), pack-reused 637\u001b[K\n",
            "Receiving objects: 100% (637/637), 231.39 MiB | 32.68 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "Checking out files: 100% (601/601), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0nG4OkcN26G"
      },
      "source": [
        "## Procesamiento de imagen\n",
        "\n",
        "1. Convertir cada imagen en una matriz.\n",
        "2. Mapear las etiquetas de cada imagen.\n",
        "3. Aumentar cada imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtXxDq1O4okc"
      },
      "source": [
        "### Procesamiento de imagen: Mapear cada imagen con etiquetas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DIAsjUd343_"
      },
      "source": [
        "<center><b>Mapear cada imagen con etiquetas</b><br><img src=\"https://drive.google.com/uc?id=1_b1xd8UxuouE3zoTwzRxq3zPxzsnTF0U\" width= 1000>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6cHrlB-5xQ4"
      },
      "source": [
        "### Procesamiento de imagen: Aumento de datos\n",
        "\n",
        "Algunas técnicas de aumento de datos:\n",
        "\n",
        "*   Rotación de imagen.\n",
        "*   Desplazamiento de la altura y ancho de la imagen.\n",
        "*   Giro horizontal y vertical de la imagen.\n",
        "*   Cambio de tamaño de la imagen.\n",
        "*   Zoom de la imagen.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1WiQYLCyavp0KlCXoHYIRT5KrjNLLR-Um\" width= 400>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NhJWjpUVBpu"
      },
      "source": [
        "#### Entrenamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5-_nrO7yn2D",
        "outputId": "7151d58d-4319-4771-b802-73ea22e3c903"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "# Aumento de datos aleatorio (Cambio de tamaño, rotación, giros, zoom, transformaciones) usando ImageDataGenerator \n",
        "training_data_generator = ImageDataGenerator(\n",
        "    rescale = 1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "\n",
        "# Directorio de la imagen\n",
        "training_image_directory = \"/content/PRO-M3-Pneumothorax-Image-Dataset/training_dataset\"\n",
        "\n",
        "# Generación de aumento de datos procesados\n",
        "training_augmented_images = training_data_generator.flow_from_directory(\n",
        "    training_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUOaQFdFVGmT"
      },
      "source": [
        "#### Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS-Jx1EB-OFg",
        "outputId": "526b7115-8545-4f61-e827-61089e611c6a"
      },
      "source": [
        "# Aumento de datos aleatorio (cambio de tamaño) usando ImageDataGenerator\n",
        "validation_data_generator = ImageDataGenerator(rescale = 1.0/255)\n",
        "\n",
        "# Directorio de la imagen\n",
        "validation_image_directory = \"/content/PRO-M3-Pneumothorax-Image-Dataset/validation_dataset\"\n",
        "\n",
        "# Generación de aumento de datos procesados\n",
        "validation_augmented_images = validation_data_generator.flow_from_directory(\n",
        "    validation_image_directory,\n",
        "    target_size=(180,180))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqKJ8zkPZs-G"
      },
      "source": [
        "#### Etiquetas de las clases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUU7UKNhyftg",
        "outputId": "1744d479-99ee-4262-efdf-efd165d7aec5"
      },
      "source": [
        "training_augmented_images.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'infected': 0, 'uninfected': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKguVEnx3O4m"
      },
      "source": [
        "##  Arquitectura de las redes neuronales convolucionales\n",
        "Un modelo CNN consiste de:\n",
        "\n",
        "1. **Capas de aprendizaje de características**:\n",
        "\n",
        "   1.1 Capas de convolución + capas de activación (RELU).\n",
        "\n",
        "   1.2 Capas de agrupación o *pooling*\n",
        "\n",
        "2. **Capas de clasificación**:\n",
        "\n",
        "   2.1 Capas para aplanar.\n",
        "\n",
        "   2.2 Capas completamente conectadas (densas) \n",
        "\n",
        "   2.3 Capas completamente conectadas (densas) con Softmax\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1OD6XteFaDvTTliIDn2xa6pP_iH_gk1xO\" width= 1500>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T-8YEZK3aj_"
      },
      "source": [
        "**Visualización de la extracción de características(convolución + Relu)**\n",
        "\n",
        "La convolución es un cálculo matemático entre dos matrices, la matriz de imágenes y la matriz de filtros, que da una nueva matriz de imágenes.\n",
        "\n",
        "\n",
        "Visualmente podemos entender que el detector de características/filtro se mueve sobre la imagen para extraer características de la misma.\n",
        "\n",
        "\n",
        "\n",
        "[<img src=\"https://drive.google.com/uc?id=1Sw7iKlkJbP_PCt6tNwhwc3VVQupG7YOi\" width= 500>](https://)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHHUNrcWC91w"
      },
      "source": [
        "## Matemáticamente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tQ9L7AzCXN3"
      },
      "source": [
        "**Conv2D Layer**\n",
        "\n",
        "La convolución es un cálculo matemático entre dos matrices 2D, la matriz de imágenes y la matriz de filtros, que da lugar a una nueva matriz de imágenes.\n",
        "\n",
        "Se toma una porción de la matriz de la imagen de entrada, llamada submatriz (de tamaño igual al tamaño del filtro), empezando por la parte superior izquierda.\n",
        "\n",
        "Esta submatriz se multiplica por la matriz del filtro. Podemos multiplicar una matriz con otra, multiplicando el primer elemento por el primer elemento de ambas matrices (el segundo elemento por el segundo elemento de ambas matrices y así sucesivamente).\n",
        "\n",
        "Después de multiplicar, el resultado se suma, lo que da el valor del 1er elemento de la nueva matriz de imagen.\n",
        "\n",
        "Luego nos desplazamos hacia la derecha en una columna y repetimos los pasos anteriores para obtener el valor del segundo elemento de la nueva matriz.\n",
        "\n",
        "Una vez terminada toda la fila, nos desplazamos una fila hacia abajo y repetimos los pasos anteriores para obtener el valor de todos los elementos de la nueva matriz, uno por uno.\n",
        "\n",
        "Todo el proceso se repite con diferentes filtros, para obtener diferentes salidas, que en conjunto es la salida de la 1ª capa Conv2D.\n",
        "\n",
        "Estas salidas de la 1ª capa Conv2D se dan a la 2ª capa Conv2D y se realizan las convoluciones.\n",
        "\n",
        "Esto se repite para todas las capas del modelo CNN.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1IRxv0-ZJb1Rm7VAS08Q29fLB0RpCTCSw\" width= 800>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZhK3L6qCW0C"
      },
      "source": [
        "**ReLU**\n",
        "\n",
        "ReLU se define como una función, y= f(x) tal que asigna x para todos los valores x > 0 y 0 para todos los valores x<0.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1p_1QMI8B926gbChOaqBHGioxW38vMhSw\" width= 600>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yV1sDPWBZsS"
      },
      "source": [
        "**MaxPooling2D**\n",
        "\n",
        "Primero, hay una matriz de entrada (por ejemplo, 4x4) y otra matriz de un tamaño específico (por ejemplo 2x2) a la que se le conoce como pool. El tamaño de la matriz pool siempre es menor que el tamaño de la matriz de entrada.\n",
        "Pool se suele usar para recursos que se almacenan listos para ser usados, en lugar de ser adquiridos y liberados después.\n",
        "\n",
        "Luego, el valor máximo se toma de la sub-matriz que tenga igual tamaño que la matriz pool.\n",
        "\n",
        "El resultado después de aplicar Max Pooling será la nueva matriz con tamaño igual a la mitad del tamaño de la matriz de entrada original\n",
        "\n",
        "Dado que nuestra matriz de entrada es de 4x4, después del max pooling, la nueva matriz será 2x2, lo que reduce la dimensión de la matriz.\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1YN6RSi6HxDj9tCgQTSm-sP6wUrJ7Iu-D\" width= 800>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hMRvgb4W7MF"
      },
      "source": [
        "## Definir el modelo de red neuronal convolucional (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOw4OJQo-p-9"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    \n",
        "    # 1a Capa de convolución y capa pooling \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # 2a Capa de convolución y capa pooling\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # 3a Capa de convolución y capa pooling\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # 4a Capa de convolución y capa pooling\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # Aplanar los resultados para ingresarlos a la capa densa\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    # Capa de clasificación\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuhJ_4N6XCle"
      },
      "source": [
        "## Resumen del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvxQyRT2-wBY",
        "outputId": "7c5833f3-88a7-4718-9d4c-9352e34b7e78"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 178, 178, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 89, 89, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 87, 87, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 43, 43, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 41, 41, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 18, 18, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10368)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               5308928   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 5,570,114\n",
            "Trainable params: 5,570,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U9aDI1zWEs6"
      },
      "source": [
        "## Visualización de las salidas intermedias de las capas de convolución\n",
        "\n",
        "\n",
        "Podemos ver la salida de las **4 capas convolucionales** (conv2d, conv2d_1, conv2d_2, conv2d_3) con capas de  **max pooling** (max_pooling2d, max_pooling2d_1, max_pooling2d_2, max_pooling2d_3)\n",
        "\n",
        "**Nota: Esta imagen está creada solo con fines explicativos.**\n",
        "\n",
        "Al comienzo de una red convolucional, el filtro (detector de características/kernel) detecta patrones simples, como líneas horizontales, líneas verticales y esquinas, formas simples. \n",
        "\n",
        "En las capas posteriores de la red, los filtros (detector de características/kernel) son complejos que detectan formas, objetos y otras estructuras complejas, lo que se hace utilizando la característica anteriormente generada y sus características simples detectadas, para construir otras más complejas. \n",
        "\n",
        "\n",
        "*Nota: A medida que profundizamos en las capas, las características se vuelven cada vez más complejas y, por lo tanto, menos interpretables visualmente. Se comienzan a programar conceptos de nivel superior, como bordes, esquinas y ángulos únicos. Las presentaciones superiores llevan cada vez menos información sobre los contenidos visuales de la imagen, y cada vez más información relacionada con la clase de la imagen, por lo que las salidas de la capa densa no se mostrarán para una explicación visual.*\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://s3-whjr-curriculum-uploads.whjr.online/b941c8bd-c137-449f-ae8f-7233735a7845.jpg\" width= 800>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNSPGf6BZxVs"
      },
      "source": [
        ""
      ]
    }
  ]
}